<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="./assets/hero-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="./assets/hero-light.svg">
    <img src="./assets/hero-light.svg" width="100%" alt="Adaptive Prompt Optimizer">
  </picture>
</p>

<p align="center">
  <a href="./LICENSE"><img src="https://img.shields.io/badge/license-MIT-3b82f6?style=for-the-badge" alt="MIT License"></a>
  <img src="https://img.shields.io/badge/type-meta--prompt-8b5cf6?style=for-the-badge" alt="Meta-Prompt">
  <img src="https://img.shields.io/badge/status-stable-10b981?style=for-the-badge" alt="Stable">
</p>

<br>

## What is APO?

**Adaptive Prompt Optimizer** transforms any conversational AI into a self-adaptive reasoning system—capable of structured self-assessment, confidence calibration, and transparent prompt generation.

Built on principles from **cognitive science**, **systems engineering**, and **AI alignment**, APO delivers a reusable text-based reasoning protocol that works across all AI platforms.

### Core Characteristics

- **Text-Only** — Works in any AI chat or reasoning model
- **Model-Agnostic** — Compatible with ChatGPT, Claude, Gemini, and emerging systems
- **Zero-Maintenance** — No dependencies, code, or updates required
- **Future-Proof** — Designed to remain valid across AI generations

> **APO is not software.** It is a structured reasoning protocol—a reproducible framework any model can execute entirely through text.

<br>

## Quick Start

**1.** Open [`FRAMEWORK.md`](./FRAMEWORK.md)  
**2.** Copy the complete meta-prompt  
**3.** Paste into your AI system (ChatGPT, Claude, Gemini, etc.)  
**4.** Run as a **system prompt** or **instruction layer**  
**5.** Follow the guided calibration

> Compatible with any conversational AI that supports structured prompts.

<br>

## Architecture

APO operates through a **six-phase adaptive reasoning cycle**, inspired by human metacognition and control theory:

<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="./assets/diagram-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="./assets/diagram-light.svg">
    <img src="./assets/diagram-light.svg" width="100%" alt="Six-Phase Reasoning Cycle">
  </picture>
</p>

<table>
<thead>
<tr>
<th width="30%">Phase</th>
<th width="70%">Function</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>0 – Self-Assessment</strong></td>
<td>Verify model capabilities and operational constraints</td>
</tr>
<tr>
<td><strong>0.5 – User Calibration</strong></td>
<td>Match reasoning depth and tone to user preference</td>
</tr>
<tr>
<td><strong>1 – Task Profiling</strong></td>
<td>Define goals, success criteria, and contextual requirements</td>
</tr>
<tr>
<td><strong>2 – System Identification</strong></td>
<td>Map available tools, knowledge access, and resources</td>
</tr>
<tr>
<td><strong>3 – Method Discovery</strong></td>
<td>Select optimal reasoning and formatting strategies</td>
</tr>
<tr>
<td><strong>4 – Prompt Assembly & Delivery</strong></td>
<td>Generate and validate the final adaptive prompt</td>
</tr>
</tbody>
</table>

<br>

## Core Principles

**1. Absolute Rule**  
Never fabricate or assume information. When uncertain, state so explicitly and propose evidence-based alternatives.

**2. Self-Assessment**  
Models must evaluate their operational boundaries and capabilities before proceeding with reasoning.

**3. Calibration**  
Depth of explanation and reasoning complexity must align with user needs and model limitations.

**4. Verification**  
Every output must include explicit rationale, confidence indicators, or validation steps.

**5. Governance**  
Embedded meta-learning, loop-prevention protocols, and reflexive mechanisms ensure bounded, auditable reasoning.

<br>

## Conceptual Foundations

APO synthesizes principles from multiple disciplines:

<table>
<thead>
<tr>
<th width="30%">Discipline</th>
<th width="70%">Contribution</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cognitive Science</strong></td>
<td>Metacognition, adaptive reasoning, uncertainty modeling</td>
</tr>
<tr>
<td><strong>Systems Engineering</strong></td>
<td>Feedback loops, control layers, verification architecture</td>
</tr>
<tr>
<td><strong>AI Alignment</strong></td>
<td>Transparency, interpretability, corrigibility principles</td>
</tr>
</tbody>
</table>

<br>

## Design Philosophy

APO is engineered to remain **valid across AI generations**—from text-only models to multimodal, agentic, and large-context systems.

Its modular, text-based structure ensures:

- **Interpretability** — Reasoning steps are explicit and human-auditable
- **Reproducibility** — Identical inputs yield consistent outputs
- **Portability** — No dependencies on specific platforms or architectures
- **Longevity** — Design principles transcend current model limitations

<br>

## Why It Matters

Modern AI systems frequently reason opaquely, making verification and trust difficult. APO addresses this by providing a research-backed foundation for adaptive, transparent cognition.

It bridges **human epistemic rigor** with **machine adaptability**, supporting:

- Research reproducibility and methodological transparency
- Ethical accountability in AI-assisted decision-making
- Trust and explainability in high-stakes applications

<br>

## Future-Proof by Design

**APO is released as a completed, finalized framework.**

- No further updates, maintenance, or modifications planned
- The protocol has been carefully optimized; changes may compromise reliability
- This repository serves as a stable reference implementation

**Use freely, cite widely, study deeply.**

For derivative work, fork the repository and clearly document any modifications to preserve attribution and integrity.

<br>

## License

Distributed under the [MIT License](./LICENSE).

© 2025 Henry Joseph Adams

<br>

---

<p align="center">
  <sub><strong>adaptive-prompt-optimizer</strong> • <a href="https://github.com/hjadmz">@hjadmz</a></sub>
</p>
