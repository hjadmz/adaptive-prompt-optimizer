# Adaptive Prompt Optimizer (APO)

![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)
![Status](https://img.shields.io/badge/status-Stable-success.svg)
![Made With](https://img.shields.io/badge/made_with-Empirical_Logic-black.svg)

Meta-prompt framework for systematic AI reasoning and adaptive prompt optimization  
**Research-backed • Self-adaptive • Future-proof • Zero-maintenance**

[Quick Start](#quick-start) • [How It Works](#how-it-works) • [Why-It-Works](#why-it-works) • [Framework Structure](#framework-structure) • [Conceptual Foundations](#conceptual-foundations) • [Integration Example](#integration-example) • [License](#license)

---

## Overview

The **Adaptive Prompt Optimizer (APO)** is a meta-prompt framework — a single text-based protocol that transforms any conversational AI into a systematic prompt-engineering agent.

Unlike libraries or code packages, APO is **purely textual** and **architecture-agnostic**.  
It provides a reproducible reasoning protocol that enables AI systems to:

- Perform structured self-assessment  
- Adapt reasoning depth dynamically  
- Calibrate user granularity and context  
- Construct verifiable, auditable prompts  
- Deliver transparent, confidence-scored outputs  

APO draws conceptually from **cognitive science**, **systems engineering**, and **alignment strategies** common in safe AI design — distilled purely through **empirical logic** and **iterative reasoning**.

---

## Quick Start

1. Copy the complete meta-prompt from [`FRAMEWORK.md`](./FRAMEWORK.md).  
2. Paste it into any advanced AI system (e.g., ChatGPT, Claude, Gemini).  
3. Run it as the *system prompt* or *base instruction layer*.  
4. Follow the AI’s guided calibration process (Phases 0–5).

You now have a **self-adaptive reasoning engine** that tailors prompts to its verified capabilities and user context.

---

## How It Works

APO functions as a **phased reasoning architecture**:

| Phase | Description |
|-------|--------------|
| **0. Self-Assessment** | AI empirically verifies its operational capabilities and constraints. |
| **0.5. User Calibration** | Adjusts reasoning granularity and explanation depth. |
| **1. Task Profiling** | Builds contextual understanding of task domain and success criteria. |
| **2. System Identification** | Determines optimal systems or frameworks (with offline fallback). |
| **3. Method Discovery** | Identifies or infers effective procedural methods. |
| **4. Prompt Construction** | Synthesizes adaptive, verifiable, and structured prompts. |
| **5. Delivery** | Outputs optimized prompt with confidence calibration and fallback guidance. |

---

## Why It Works

APO’s strength lies in **structured adaptability**:

1. **Empirical Verification** — No assumptions; all reasoning is evidence-based.  
2. **Bounded Adaptation** — Never exceeds verified capability without user input.  
3. **Transparency** — Each reasoning step and confidence rating is explicit.  
4. **Governed Loops** — Internal self-auditing is bounded and non-recursive.  
5. **Human-Aligned Clarity** — All explanations scale with user expertise.  

This produces **reliable**, **interpretable**, and **reproducible** reasoning across any AI model or deployment environment.

---

## Framework Structure

### 📘 Core Flow

Absolute Rule
↓
Phase 0 → Phase 0.5 → Phase 1
↓
Research Tools? — Yes → Phase 2A (Online) | No → Phase 2B (Offline)
↓
Phase 3 → Phase 4 → Phase 5
↓
Governance Architecture (Meta-Learning Reflex, Loop Prevention, Confidence Calibration)

### 📊 Visual Flowchart

![Adaptive Prompt Optimizer Flowchart](./assets/APO_Flowchart.png)

> The flowchart visualizes APO’s full reasoning cycle — including governance oversight, adaptive branching logic, and refinement feedback.

---

## Conceptual Foundations

APO’s design draws from interdisciplinary research:

- **Cognitive Science** — Metacognition, uncertainty modeling, adaptive reasoning.  
- **Systems Engineering** — Modular verification loops, layered self-assessment, constraint feedback.  
- **AI Alignment** — Safe reasoning boundaries, corrigibility, and interpretability.  

Distilled into a single **self-contained textual framework**, requiring no dependencies, libraries, or runtime environment.

---

## Integration Example

Example system setup:

```text
SYSTEM:
Load Adaptive Prompt Optimizer (APO)
Run Phases 0–5 sequentially.
Apply governance and confidence calibration at each phase.
Return final prompt and reasoning summary.
This framework can serve as the foundation for meta-agents, research models, or advanced reasoning frameworks.
Governance Architecture
APO maintains a continuous oversight layer composed of:
Meta-Learning Reflex — Evaluates efficiency and reasoning sufficiency post-task.
Learning Boundary Principle — Prevents extrapolation beyond verified limits.
Context Refresh Mechanism — Reassesses context to avoid drift in long sessions.
Temporal Abstraction Layer — Distinguishes timeless logic from time-sensitive data.
Loop Prevention — Halts recursive re-entry without new information.
Each principle ensures safe, interpretable, and future-proof adaptive reasoning.
License
Licensed under the MIT License.
Free for use, modification, and redistribution with attribution.
© 2025 Henry Joseph Adams
“A framework for thinking, not just prompting.”
