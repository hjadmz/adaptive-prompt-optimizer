# Adaptive Prompt Optimizer (APO)

<div align="center">

![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)

**Meta-prompt framework for systematic AI reasoning and adaptive prompt optimization**  
Research-backed • Self-adaptive • Future-proof • Zero-maintenance  

[Quick Start](#quick-start) • [How-It-Works](#how-it-works) • [Why-It-Works](#why-it-works) • [Examples](#examples) • [FAQ](#faq)

</div>

---

## Overview

The **Adaptive Prompt Optimizer (APO)** is a meta-prompt framework — a single text file that transforms any conversational AI into a **systematic prompt-engineering agent**.

Unlike libraries or code packages, APO is purely text-based.  
It functions as a structured reasoning protocol that guides AI systems through **self-assessment, contextual calibration, and adaptive prompt synthesis**.

Designed for **researchers, developers, and professionals**, APO enables reproducible, interpretable, and architecture-agnostic prompt optimization.

---

## Key Features

- ✅ Detects and verifies available tools or capabilities  
- ✅ Adapts reasoning depth to user preferences  
- ✅ Conducts research and inference when external access is enabled  
- ✅ Constructs task-specific, optimized prompts  
- ✅ Reports confidence levels and reasoning transparency  
- ❌ Never fabricates or hallucinates information  

**Result:** reliable, consistent, and context-aware prompt generation.

---

## Why It Works

APO integrates principles from **cognitive science**, **information theory**, and **systems reasoning** to ensure adaptability across AI architectures.

| Principle | Function |
|------------|-----------|
| **Capability Verification** | Confirms what the AI can empirically do before acting |
| **Adaptive Reasoning Depth** | Scales explanations and logic based on user preference |
| **Structured Phase Design** | Divides reasoning into modular, auditable phases |
| **Meta-Learning Reflex** | Evaluates optimization quality and efficiency |
| **Temporal Intelligence** | Distinguishes timeless logic from time-sensitive data |

Together, these principles make APO **self-correcting, interpretable, and architecture-resilient**.

---

## Why It Matters

AI systems often produce inconsistent or opaque reasoning.  
APO standardizes how models think — ensuring **clarity, auditability, and long-term interoperability** across evolving architectures.

---

## Quick Start

1. **Open [`FRAMEWORK.md`](./FRAMEWORK.md)**  
   Review the complete framework file.

2. **Copy the contents**  
   Copy the entire framework text.

3. **Paste into any AI chat**  
   Start a new session and paste it directly.

4. **Describe your task**  
   Example: “Optimize a prompt for literature review” or “Create a system prompt for product strategy.”

5. **Follow the guided process**  
   The AI will progress through structured phases, assess its own capabilities, and generate a tailored optimized prompt.

---

## How It Works

The framework executes a structured reasoning sequence:

Phase 0: Self-Assessment → Detects tools and verifies system state
Phase 0.5: User Calibration → Adjusts reasoning depth and communication style
Phase 1: Task Profiling → Gathers task context and constraints
Phase 2: System Identification → Evaluates and ranks viable tools or systems
Phase 3: Method Discovery → Identifies effective techniques or reasoning models
Phase 4: Prompt Construction → Synthesizes and validates the optimized prompt
Phase 5: Delivery → Returns prompt, reasoning trace, and confidence report

Each phase builds upon the previous, forming a **closed reasoning loop** with built-in checks for uncertainty, redundancy, and temporal drift.

---

## Examples

### Academic Writing
> *“Optimize a prompt for systematic literature reviews.”*  
The framework verifies external access, gathers parameters, and produces a publication-ready review prompt.

### Technical Documentation
> *“Create a prompt for API documentation.”*  
It analyzes scope, audience, and best practices to deliver a clean, structured documentation template.

### Business Strategy
> *“Build a prompt for competitive analysis.”*  
It identifies relevant systems, defines criteria, and outputs a strategic prompt with transparent reasoning.

---

## FAQ

**Do I need to install anything?**  
No. APO is text-only — copy, paste, and use.

**Which AI systems are supported?**  
Any conversational model that accepts text input.

**Do I need coding experience?**  
No. APO is designed for both technical and non-technical users.

**Can I modify it?**  
Yes. It’s open-source under the MIT License — adapt it for your workflows.

**How do I know it’s working?**  
When the AI begins referencing phases (e.g., “Phase 0: Self-Assessment”) or evaluating its own capabilities, the framework is active.  
For full logic and structure, see [`FRAMEWORK.md`](FRAMEWORK.md).

---

## Maintenance

This repository is **self-contained and zero-maintenance**.  
The framework has no dependencies and is designed to remain compatible with future AI systems.

---

## License

This project is distributed under the [MIT License](LICENSE).  
You are free to use, modify, and distribute it for research or commercial purposes with attribution.

---

## Recommended Repository Topics

prompt-engineering
prompt-optimization
meta-prompt
ai-reasoning
systematic-reasoning
adaptive-ai
llm-framework
ai-alignment
research-tool
future-proof

---

## Citation (Optional)

If referenced in research or documentation:

@software{adaptive_prompt_optimizer,
title = {Adaptive Prompt Optimizer (APO)},
author = {Adams, Henry},
year = {2025},
url = {https://github.com/henryadams/adaptive-prompt-optimizer},
license = {MIT}
}

---

## Summary

The **Adaptive Prompt Optimizer** is a minimal yet powerful meta-framework for controlled AI reasoning — a single prompt that teaches models *how to think before they act.*  
It is **academically grounded**, **implementation-independent**, and designed for **long-term interoperability** across AI systems.

---
