# Adaptive Prompt Optimizer (APO)

<p align="center">
  <picture>
  <source media="(prefers-color-scheme: dark)" srcset="./assets/APO_logo_dark.svg">
  <source media="(prefers-color-scheme: light)" srcset="./assets/APO_logo_light.svg">
  <img src="./assets/APO_logo_light.svg" alt="Adaptive Prompt Optimizer logo" width="340" style="border-radius: 8px;">
</picture>

  
  <b>Meta-prompt framework for systematic AI reasoning and adaptive prompt optimization</b><br>
  
  <em>Research-inspired • Self-adaptive • Future-proof • Zero-maintenance</em>
</p>

<p align="center">
  <a href="./LICENSE"><img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="License: MIT"></a>
  <img src="https://img.shields.io/badge/Status-Stable-success.svg" alt="Status: Stable">
  <img src="https://img.shields.io/badge/Made_with-Empirical_Logic-black.svg" alt="Made with Empirical Logic">
</p>

---

## 🧠 Overview

**Adaptive Prompt Optimizer (APO)** is a self-contained meta-prompting framework that transforms any conversational AI into a **systematic prompt-engineering agent**.

Unlike libraries or code packages, APO is **purely textual and model-agnostic**.  
It defines a reproducible reasoning protocol that enables AI systems to:

- Perform structured self-assessment  
- Adapt reasoning depth dynamically  
- Calibrate user granularity and context  
- Construct verifiable, auditable prompts  
- Deliver transparent, confidence-scored outputs  

Rooted in **cognitive science**, **systems engineering**, and **AI alignment**, APO distills empirical reasoning into a single, portable framework.

---

## 🚀 Quick Start

1. **Copy** the complete meta-prompt from [`FRAMEWORK.md`](./FRAMEWORK.md).  
2. **Paste** it into any advanced AI system (e.g., ChatGPT, Claude, Gemini).  
3. **Run** it as the *system prompt* or *base instruction layer*.  
4. **Follow** the guided calibration process (Phases 0–5).

Requires **no installation, dependencies, or setup**.

---

## ⚙️ How It Works

APO operates through a **six-phase reasoning architecture**:

| Phase | Description |
|:------|:-------------|
| **0 – Self-Assessment** | Verifies the AI’s operational capabilities and constraints. |
| **0.5 – User Calibration** | Adjusts reasoning granularity and explanation depth. |
| **1 – Task Profiling** | Defines context, goals, and success criteria. |
| **2 – System Identification** | Determines optimal frameworks or tools (online/offline). |
| **3 – Method Discovery** | Identifies or infers effective procedural strategies. |
| **4 – Prompt Construction** | Synthesizes adaptive, verifiable, and structured prompts. |
| **5 – Delivery** | Outputs optimized prompts with confidence calibration and fallback guidance. |

Each phase reinforces **transparency**, **accuracy**, and **bounded adaptability**.

---

## 🧩 Framework Structure

### 📘 Core Flow

```
Absolute Rule
↓
Phase 0 → Phase 0.5 → Phase 1
↓
Research Tools? — Yes → Phase 2A (Online) | No → Phase 2B (Offline)
↓
Phase 3 → Phase 4 → Phase 5
↓
Governance Architecture (Meta-Learning Reflex, Loop Prevention, Confidence Calibration)
```

### 📊 Visual Flowchart

<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="./assets/APO_Flowchart_dark.png">
    <source media="(prefers-color-scheme: light)" srcset="./assets/APO_Flowchart_light.png">
    <img src="./assets/APO_Flowchart_light.png" alt="Adaptive Prompt Optimizer Flowchart" width="700">
  </picture><br>
  <em>Visualization of APO’s reasoning process — structured, auditable, and adaptive.</em>
</p>

---

## 💡 Example Usage

```text
SYSTEM:
Load Adaptive Prompt Optimizer (APO).
Run Phases 0–5 sequentially.
Apply governance and confidence calibration at each phase.
Return the optimized prompt along with a reasoning summary.

This framework can serve as the foundation for meta-agents, research models, or adaptive reasoning pipelines.
```

---

## 🧭 Conceptual Foundations

APO’s design draws from interdisciplinary research in:

- **Cognitive Science** — Metacognition, uncertainty modeling, adaptive reasoning.  
- **Systems Engineering** — Modular verification loops, constraint feedback.  
- **AI Alignment** — Safe reasoning boundaries, corrigibility, interpretability.  

All distilled into a **single self-contained textual framework**, requiring no code execution or dependencies.

---

## 🧾 License

This project is distributed under the [MIT License](./LICENSE).  
© 2025 Henry Joseph Adams — All rights reserved.

---

## 🔗 Reference

**Adaptive Prompt Optimizer (APO)** — GitHub Repository  
<https://github.com/hjadmz/adaptive-prompt-optimizer>

---

## 🧠 Appendix — Full Meta-Prompt

> The complete Adaptive Prompt Optimizer framework is available in [`FRAMEWORK.md`](./FRAMEWORK.md).  
> The framework implements all operational phases below for adaptive, evidence-based prompt construction.

---

### Phase 0 – Self-Assessment and Capability Inventory
AI empirically determines its functional boundaries and tool accessibility before optimization.

### Phase 0.5 – User Granularity Calibration
Adjusts explanation depth, verbosity, and reasoning style according to user preference.

### Phase 1 – Task and User Profiling
Establishes domain context, goals, constraints, and user proficiency to tailor reasoning scope.

### Phase 2 – System Identification
Chooses the optimal framework, dataset, or reference model (online or offline), ranked by confidence and constraint match.

### Phase 3 – Method and Format Discovery
Finds or infers procedural logic and output formats aligned with user intent and model capacity.

### Phase 4 – Prompt Construction
Synthesizes an auditable, adaptive prompt incorporating empirical reasoning, verification clauses, and fallback logic.

### Phase 5 – Delivery
Produces the final optimized prompt, annotated with confidence metrics, fallback paths, and reasoning summaries.

---

### Governance Architecture

- **Meta-Learning Reflex** — Continuously self-evaluates reasoning efficiency post-execution.  
- **Learning Boundary Principle** — Adapts only within verified capabilities.  
- **Context Refresh Mechanism** — Periodically revalidates assumptions.  
- **Temporal Abstraction Layer** — Handles time-sensitive reasoning explicitly.  
- **Loop Prevention Protocol** — Ensures finite reasoning cycles.

---

### Core Operating Rules

- Never fabricate; acknowledge limitations.  
- Verify all data sources and capabilities.  
- Calibrate confidence by empirical validation.  
- Favor simplicity and interpretability over verbosity.  
- Optimize adaptively for the current system and user context.  
- Preserve reproducibility and safety in reasoning outputs.

---

### Final Principles

> APO formalizes a **structured reasoning architecture** for AI models — ensuring transparency, bounded adaptation, and reliability across evolving systems.  
> Designed for **longevity**, **clarity**, and **reusability** in both research and applied AI environments.
