# Adaptive Prompt Optimizer (APO)

<p align="center">
  <img src="./assets/APO_logo.png" alt="Adaptive Prompt Optimizer Logo" width="120"><br>
  <b>Meta-prompt framework for systematic AI reasoning and adaptive prompt optimization</b><br>
  <em>Research-inspired â€¢ Self-adaptive â€¢ Future-proof â€¢ Zero-maintenance</em>
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/hjadmz/adaptive-prompt-optimizer/main/assets/divider.svg" width="240" alt="divider">
</p>

<p align="center">
  <a href="./LICENSE"><img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="License: MIT"></a>
  <img src="https://img.shields.io/badge/Status-Stable-success.svg" alt="Status: Stable">
  <img src="https://img.shields.io/badge/Made_with-Empirical_Logic-black.svg" alt="Made with Empirical Logic">
</p>

---

## ğŸ§  Overview

**Adaptive Prompt Optimizer (APO)** is a self-contained meta-prompting framework that transforms any conversational AI into a **systematic prompt-engineering agent**.

Unlike libraries or code packages, APO is **purely textual** and **model-agnostic**.  
It defines a reproducible reasoning protocol that enables AI systems to:

- Perform structured self-assessment  
- Adapt reasoning depth dynamically  
- Calibrate responses to user context  
- Produce verifiable, auditable outputs  

Grounded in **cognitive science**, **systems engineering**, and **AI alignment**, APO distills these principles into a single portable framework.

---

## ğŸš€ Quick Start

1. **Copy** the full prompt from [`FRAMEWORK.md`](./FRAMEWORK.md).  
2. **Paste** it into any large language model (e.g., ChatGPT, Claude, Gemini).  
3. **Run** it as the *system* or *instruction* prompt.  
4. **Follow** the guided calibration sequence (Phases 0 â€“ 5).

No installation, dependencies, or setup required.

---

## âš™ï¸ How It Works

APO operates through a **six-phase reasoning architecture**:

| Phase | Function |
|:------|:----------|
| **0 â€“ Self-Assessment** | Evaluates model capabilities and constraints. |
| **0.5 â€“ User Calibration** | Adjusts reasoning depth and explanation style. |
| **1 â€“ Task Profiling** | Defines goals, domain, and success criteria. |
| **2 â€“ System Identification** | Selects optimal frameworks or methods (online/offline). |
| **3 â€“ Method Discovery** | Derives effective procedural reasoning steps. |
| **4 â€“ Prompt Construction** | Synthesizes a verifiable, adaptive final prompt. |
| **5 â€“ Delivery** | Outputs structured results with confidence calibration. |

Each phase reinforces **transparency**, **accuracy**, and **adaptability** across AI reasoning tasks.

---

## ğŸ§© Framework Structure

### ğŸ“˜ Core Flow
```
Absolute Rule
â†“
Phase 0 â†’ Phase 0.5 â†’ Phase 1
â†“
Research Tools? â€” Yes â†’ Phase 2A (Online) | No â†’ Phase 2B (Offline)
â†“
Phase 3 â†’ Phase 4 â†’ Phase 5
â†“
Governance Architecture (Meta-Learning Reflex, Loop Prevention, Confidence Calibration)
```

### ğŸ“Š Visual Flowchart
<p align="center">
  <img src="./assets/APO_Flowchart.png" alt="APO Flowchart" width="600"><br>
  <em>Visualization of APOâ€™s reasoning loop and adaptive branching flow.</em>
</p>

---

## ğŸ’¡ Example Usage
```text
SYSTEM:
Load Adaptive Prompt Optimizer (APO).
Run Phases 0â€“5 sequentially.
Apply governance and confidence calibration at each phase.
Return optimized prompt + reasoning summary.
```

APO can serve as a foundation for **meta-agents, research frameworks, and reasoning pipelines**.

---

## ğŸ“ License
This project is licensed under the [MIT License](./LICENSE).  
Â© 2025 Henry Joseph Adams â€” All rights reserved.

---

## ğŸ”— Reference
Adaptive Prompt Optimizer (APO). GitHub Repository.  
<https://github.com/hjadmz/adaptive-prompt-optimizer>
