# Adaptive Prompt Optimizer (APO)

![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)
![Status](https://img.shields.io/badge/status-Stable-success.svg)
![Made With](https://img.shields.io/badge/made_with-Empirical_Logic-black.svg)

Meta-prompt framework for systematic AI reasoning and adaptive prompt optimization  
**Research-backed â€¢ Self-adaptive â€¢ Future-proof â€¢ Zero-maintenance**

[Quick Start](#quick-start) â€¢ [How It Works](#how-it-works) â€¢ [Why-It-Works](#why-it-works) â€¢ [Framework Structure](#framework-structure) â€¢ [Conceptual Foundations](#conceptual-foundations) â€¢ [Integration Example](#integration-example) â€¢ [License](#license)

---

## Overview

The **Adaptive Prompt Optimizer (APO)** is a meta-prompt framework â€” a single text-based protocol that transforms any conversational AI into a systematic prompt-engineering agent.

Unlike libraries or code packages, APO is **purely textual** and **architecture-agnostic**.  
It provides a reproducible reasoning protocol that enables AI systems to:

- Perform structured self-assessment  
- Adapt reasoning depth dynamically  
- Calibrate user granularity and context  
- Construct verifiable, auditable prompts  
- Deliver transparent, confidence-scored outputs  

APO draws conceptually from **cognitive science**, **systems engineering**, and **alignment strategies** common in safe AI design â€” distilled purely through **empirical logic** and **iterative reasoning**.

---

## Quick Start

1. Copy the complete meta-prompt from [`FRAMEWORK.md`](./FRAMEWORK.md).  
2. Paste it into any advanced AI system (e.g., ChatGPT, Claude, Gemini).  
3. Run it as the *system prompt* or *base instruction layer*.  
4. Follow the AIâ€™s guided calibration process (Phases 0â€“5).

You now have a **self-adaptive reasoning engine** that tailors prompts to its verified capabilities and user context.

---

## How It Works

APO functions as a **phased reasoning architecture**:

| Phase | Description |
|-------|--------------|
| **0. Self-Assessment** | AI empirically verifies its operational capabilities and constraints. |
| **0.5. User Calibration** | Adjusts reasoning granularity and explanation depth. |
| **1. Task Profiling** | Builds contextual understanding of task domain and success criteria. |
| **2. System Identification** | Determines optimal systems or frameworks (with offline fallback). |
| **3. Method Discovery** | Identifies or infers effective procedural methods. |
| **4. Prompt Construction** | Synthesizes adaptive, verifiable, and structured prompts. |
| **5. Delivery** | Outputs optimized prompt with confidence calibration and fallback guidance. |

---

## Why It Works

APOâ€™s strength lies in **structured adaptability**:

1. **Empirical Verification** â€” No assumptions; all reasoning is evidence-based.  
2. **Bounded Adaptation** â€” Never exceeds verified capability without user input.  
3. **Transparency** â€” Each reasoning step and confidence rating is explicit.  
4. **Governed Loops** â€” Internal self-auditing is bounded and non-recursive.  
5. **Human-Aligned Clarity** â€” All explanations scale with user expertise.  

This produces **reliable**, **interpretable**, and **reproducible** reasoning across any AI model or deployment environment.

---

## Framework Structure

### ğŸ“˜ Core Flow

Absolute Rule
â†“
Phase 0 â†’ Phase 0.5 â†’ Phase 1
â†“
Research Tools? â€” Yes â†’ Phase 2A (Online) | No â†’ Phase 2B (Offline)
â†“
Phase 3 â†’ Phase 4 â†’ Phase 5
â†“
Governance Architecture (Meta-Learning Reflex, Loop Prevention, Confidence Calibration)

### ğŸ“Š Visual Flowchart

![Adaptive Prompt Optimizer Flowchart](./assets/APO_Flowchart.png)

> The flowchart visualizes APOâ€™s full reasoning cycle â€” including governance oversight, adaptive branching logic, and refinement feedback.

---

## Conceptual Foundations

APOâ€™s design draws from interdisciplinary research:

- **Cognitive Science** â€” Metacognition, uncertainty modeling, adaptive reasoning.  
- **Systems Engineering** â€” Modular verification loops, layered self-assessment, constraint feedback.  
- **AI Alignment** â€” Safe reasoning boundaries, corrigibility, and interpretability.  

Distilled into a single **self-contained textual framework**, requiring no dependencies, libraries, or runtime environment.

---

## Integration Example

Example system setup:

```text
SYSTEM:
Load Adaptive Prompt Optimizer (APO)
Run Phases 0â€“5 sequentially.
Apply governance and confidence calibration at each phase.
Return final prompt and reasoning summary.
This framework can serve as the foundation for meta-agents, research models, or advanced reasoning frameworks.
Governance Architecture
APO maintains a continuous oversight layer composed of:
Meta-Learning Reflex â€” Evaluates efficiency and reasoning sufficiency post-task.
Learning Boundary Principle â€” Prevents extrapolation beyond verified limits.
Context Refresh Mechanism â€” Reassesses context to avoid drift in long sessions.
Temporal Abstraction Layer â€” Distinguishes timeless logic from time-sensitive data.
Loop Prevention â€” Halts recursive re-entry without new information.
Each principle ensures safe, interpretable, and future-proof adaptive reasoning.
License
Licensed under the MIT License.
Free for use, modification, and redistribution with attribution.
Â© 2025 Henry Joseph Adams
â€œA framework for thinking, not just prompting.â€
