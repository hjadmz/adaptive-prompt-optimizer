# Adaptive Prompt Optimizer (APO)

<p align="center">
  <picture>
  <source media="(prefers-color-scheme: dark)" srcset="./assets/APO_logo_dark.svg">
  <source media="(prefers-color-scheme: light)" srcset="./assets/APO_logo_light.svg">
  <img src="./assets/APO_logo_light.svg" alt="Adaptive Prompt Optimizer logo" width="340" style="border-radius: 8px;">
</picture>

  
  <b>Meta-prompt framework for systematic AI reasoning and adaptive prompt optimization</b><br>
  
  <em>Research-inspired â€¢ Self-adaptive â€¢ Future-proof â€¢ Zero-maintenance</em>
</p>

<p align="center">
  <a href="./LICENSE"><img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="License: MIT"></a>
  <img src="https://img.shields.io/badge/Status-Stable-success.svg" alt="Status: Stable">
  <img src="https://img.shields.io/badge/Made_with-Empirical_Logic-black.svg" alt="Made with Empirical Logic">
</p>

---

## ğŸ§  Overview

**Adaptive Prompt Optimizer (APO)** is a self-contained meta-prompting framework that transforms any conversational AI into a **systematic prompt-engineering agent**.

Unlike libraries or code packages, APO is **purely textual and model-agnostic**.  
It defines a reproducible reasoning protocol that enables AI systems to:

- Perform structured self-assessment  
- Adapt reasoning depth dynamically  
- Calibrate user granularity and context  
- Construct verifiable, auditable prompts  
- Deliver transparent, confidence-scored outputs  

Rooted in **cognitive science**, **systems engineering**, and **AI alignment**, APO distills empirical reasoning into a single, portable framework.

---

## ğŸš€ Quick Start

1. **Copy** the complete meta-prompt from [`FRAMEWORK.md`](./FRAMEWORK.md).  
2. **Paste** it into any advanced AI system (e.g., ChatGPT, Claude, Gemini).  
3. **Run** it as the *system prompt* or *base instruction layer*.  
4. **Follow** the guided calibration process (Phases 0â€“5).

Requires **no installation, dependencies, or setup**.

---

## âš™ï¸ How It Works

APO operates through a **six-phase reasoning architecture**:

| Phase | Description |
|:------|:-------------|
| **0 â€“ Self-Assessment** | Verifies the AIâ€™s operational capabilities and constraints. |
| **0.5 â€“ User Calibration** | Adjusts reasoning granularity and explanation depth. |
| **1 â€“ Task Profiling** | Defines context, goals, and success criteria. |
| **2 â€“ System Identification** | Determines optimal frameworks or tools (online/offline). |
| **3 â€“ Method Discovery** | Identifies or infers effective procedural strategies. |
| **4 â€“ Prompt Construction** | Synthesizes adaptive, verifiable, and structured prompts. |
| **5 â€“ Delivery** | Outputs optimized prompts with confidence calibration and fallback guidance. |

Each phase reinforces **transparency**, **accuracy**, and **bounded adaptability**.

---

## ğŸ§© Framework Structure

### ğŸ“˜ Core Flow

```
Absolute Rule
â†“
Phase 0 â†’ Phase 0.5 â†’ Phase 1
â†“
Research Tools? â€” Yes â†’ Phase 2A (Online) | No â†’ Phase 2B (Offline)
â†“
Phase 3 â†’ Phase 4 â†’ Phase 5
â†“
Governance Architecture (Meta-Learning Reflex, Loop Prevention, Confidence Calibration)
```

### ğŸ“Š Visual Flowchart

<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="./assets/APO_Flowchart_dark.png">
    <source media="(prefers-color-scheme: light)" srcset="./assets/APO_Flowchart_light.png">
    <img src="./assets/APO_Flowchart_light.png" alt="Adaptive Prompt Optimizer Flowchart" width="700">
  </picture><br>
  <em>Visualization of APOâ€™s reasoning process â€” structured, auditable, and adaptive.</em>
</p>

---

## ğŸ’¡ Example Usage

```text
SYSTEM:
Load Adaptive Prompt Optimizer (APO).
Run Phases 0â€“5 sequentially.
Apply governance and confidence calibration at each phase.
Return the optimized prompt along with a reasoning summary.

This framework can serve as the foundation for meta-agents, research models, or adaptive reasoning pipelines.
```

---

## ğŸ§­ Conceptual Foundations

APOâ€™s design draws from interdisciplinary research in:

- **Cognitive Science** â€” Metacognition, uncertainty modeling, adaptive reasoning.  
- **Systems Engineering** â€” Modular verification loops, constraint feedback.  
- **AI Alignment** â€” Safe reasoning boundaries, corrigibility, interpretability.  

All distilled into a **single self-contained textual framework**, requiring no code execution or dependencies.

---

## ğŸ§¾ License

This project is distributed under the [MIT License](./LICENSE).  
Â© 2025 Henry Joseph Adams â€” All rights reserved.

---

## ğŸ”— Reference

**Adaptive Prompt Optimizer (APO)** â€” GitHub Repository  
<https://github.com/hjadmz/adaptive-prompt-optimizer>

---

## ğŸ§  Appendix â€” Full Meta-Prompt

> The complete Adaptive Prompt Optimizer framework is available in [`FRAMEWORK.md`](./FRAMEWORK.md).  
> The framework implements all operational phases below for adaptive, evidence-based prompt construction.

---

### Phase 0 â€“ Self-Assessment and Capability Inventory
AI empirically determines its functional boundaries and tool accessibility before optimization.

### Phase 0.5 â€“ User Granularity Calibration
Adjusts explanation depth, verbosity, and reasoning style according to user preference.

### Phase 1 â€“ Task and User Profiling
Establishes domain context, goals, constraints, and user proficiency to tailor reasoning scope.

### Phase 2 â€“ System Identification
Chooses the optimal framework, dataset, or reference model (online or offline), ranked by confidence and constraint match.

### Phase 3 â€“ Method and Format Discovery
Finds or infers procedural logic and output formats aligned with user intent and model capacity.

### Phase 4 â€“ Prompt Construction
Synthesizes an auditable, adaptive prompt incorporating empirical reasoning, verification clauses, and fallback logic.

### Phase 5 â€“ Delivery
Produces the final optimized prompt, annotated with confidence metrics, fallback paths, and reasoning summaries.

---

### Governance Architecture

- **Meta-Learning Reflex** â€” Continuously self-evaluates reasoning efficiency post-execution.  
- **Learning Boundary Principle** â€” Adapts only within verified capabilities.  
- **Context Refresh Mechanism** â€” Periodically revalidates assumptions.  
- **Temporal Abstraction Layer** â€” Handles time-sensitive reasoning explicitly.  
- **Loop Prevention Protocol** â€” Ensures finite reasoning cycles.

---

### Core Operating Rules

- Never fabricate; acknowledge limitations.  
- Verify all data sources and capabilities.  
- Calibrate confidence by empirical validation.  
- Favor simplicity and interpretability over verbosity.  
- Optimize adaptively for the current system and user context.  
- Preserve reproducibility and safety in reasoning outputs.

---

### Final Principles

> APO formalizes a **structured reasoning architecture** for AI models â€” ensuring transparency, bounded adaptation, and reliability across evolving systems.  
> Designed for **longevity**, **clarity**, and **reusability** in both research and applied AI environments.
