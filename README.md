<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="./assets/hero-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="./assets/hero-light.svg">
    <img src="./assets/hero-light.svg" width="100%" alt="Adaptive Prompt Optimizer">
  </picture>
</p>

<p align="center">
  <a href="./LICENSE"><img src="https://img.shields.io/badge/license-MIT-3b82f6?style=for-the-badge" alt="MIT License"></a>
  <img src="https://img.shields.io/badge/type-meta--prompt-8b5cf6?style=for-the-badge" alt="Meta-Prompt">
  <img src="https://img.shields.io/badge/status-stable-10b981?style=for-the-badge" alt="Stable">
</p>

<br>

## What is APO?

**Adaptive Prompt Optimizer** transforms any conversational AI into a self-adaptive reasoning system â€” capable of structured self-assessment, confidence calibration, and transparent prompt generation.

Built on principles from **cognitive science**, **systems engineering**, and **AI alignment**, APO delivers a reusable text-based reasoning protocol that works across all AI platforms.

### Core Characteristics

- **Text-Only** â€” Works in any AI chat or reasoning model  
- **Model-Agnostic** â€” Compatible with ChatGPT, Claude, Gemini, and emerging systems  
- **Zero-Maintenance** â€” No dependencies, code, or updates required  
- **Future-Proof** â€” Designed to remain valid across AI generations  

> **APO is not software.**  
> It is a structured reasoning protocol â€” a reproducible framework any model can execute entirely through text.

<br>

## Quick Start

**1.** Open [`FRAMEWORK.md`](./FRAMEWORK.md)  
**2.** Copy the complete meta-prompt  
**3.** Paste into your AI system (ChatGPT, Claude, Gemini, etc.)  
**4.** Run as a **system prompt** or **instruction layer**  
**5.** Follow the guided calibration  

> Compatible with any conversational AI that supports structured prompts.

<br>

## Architecture

APO operates through a **six-phase adaptive reasoning cycle**, inspired by human metacognition and control theory:

<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="./assets/diagram-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="./assets/diagram-light.svg">
    <img src="./assets/diagram-light.svg" width="100%" alt="Six-Phase Reasoning Cycle">
  </picture>
</p>

<table>
<thead>
<tr>
<th width="30%">Phase</th>
<th width="70%">Function</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>0 â€“ Self-Assessment</strong></td>
<td>Verify model capabilities and operational constraints</td>
</tr>
<tr>
<td><strong>0.5 â€“ User Calibration</strong></td>
<td>Match reasoning depth and tone to user preference</td>
</tr>
<tr>
<td><strong>1 â€“ Task Profiling</strong></td>
<td>Define goals, success criteria, and contextual requirements</td>
</tr>
<tr>
<td><strong>2 â€“ System Identification</strong></td>
<td>Map available tools, knowledge access, and resources</td>
</tr>
<tr>
<td><strong>3 â€“ Method Discovery</strong></td>
<td>Select optimal reasoning and formatting strategies</td>
</tr>
<tr>
<td><strong>4 â€“ Prompt Assembly & Delivery</strong></td>
<td>Generate and validate the final adaptive prompt</td>
</tr>
</tbody>
</table>

<br>

## Core Principles

**1. Absolute Rule**  
Never fabricate or assume information. When uncertain, state so explicitly and propose evidence-based alternatives.

**2. Self-Assessment**  
Models must evaluate their operational boundaries and capabilities before proceeding with reasoning.

**3. Calibration**  
Reasoning depth and complexity must align with user needs and model limitations.

**4. Verification**  
Every output must include rationale, confidence indicators, or validation steps.

**5. Governance**  
Embedded meta-learning and loop-prevention protocols ensure bounded, auditable reasoning.

<br>

## Conceptual Foundations

APO synthesizes principles from multiple disciplines:

<table>
<thead>
<tr>
<th width="30%">Discipline</th>
<th width="70%">Contribution</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cognitive Science</strong></td>
<td>Metacognition, adaptive reasoning, uncertainty modeling</td>
</tr>
<tr>
<td><strong>Systems Engineering</strong></td>
<td>Feedback loops, control layers, verification architecture</td>
</tr>
<tr>
<td><strong>AI Alignment</strong></td>
<td>Transparency, interpretability, corrigibility principles</td>
</tr>
</tbody>
</table>

<br>

## Design Philosophy

APO is engineered to remain **valid across AI generations** â€” from text-only models to multimodal, agentic, and large-context systems.

Its modular, text-based structure ensures:

- **Interpretability** â€” Reasoning steps are explicit and human-auditable  
- **Reproducibility** â€” Identical inputs yield consistent outputs  
- **Portability** â€” No dependencies on specific platforms or architectures  
- **Longevity** â€” Design principles transcend current model limitations  

<br>

## Why It Matters

Modern AI systems frequently reason opaquely, making verification and trust difficult.  
APO provides a **research-backed foundation** for adaptive, transparent cognition.

It bridges **human epistemic rigor** with **machine adaptability**, supporting:

- Research reproducibility and methodological transparency  
- Ethical accountability in AI-assisted decision-making  
- Trust and explainability in high-stakes applications  

<br>

## Future-Proof by Design

**APO is released as a completed, finalized framework.**

- No further updates or maintenance required  
- Optimized for reliability and long-term reproducibility  
- This repository serves as a stable, reference-grade implementation  

**Use freely. Cite widely. Study deeply.**  
For derivative work, fork the repository and document modifications clearly to preserve attribution and integrity.

<br>

## ðŸ—‚ Repository Structure

```text
â”œâ”€â”€ FRAMEWORK.md        # Full APO meta-prompt
â”œâ”€â”€ assets/             # Logos, diagrams, and SVG visuals
â””â”€â”€ LICENSE             # MIT License
